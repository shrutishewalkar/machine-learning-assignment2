{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9668bbec-ab78-480b-ae5b-ef29b249bb90",
   "metadata": {},
   "source": [
    "#### Que1: define overfitting and underfitting in machine learning. what are the consequences of each , and how can they be mitigated?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d620f5e-b53b-4448-81fd-314d2cb48937",
   "metadata": {},
   "source": [
    "Ans: underfitting means that your model makes accurate, but initially incorrect predictions.in this case , train error is large and val/test error is too large.  overfitting means that your model makes not accurate predictions . in this case, train erroe is very small and val/test erroe is large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d9e58b-831a-4768-81f1-f23ef4cf5cc2",
   "metadata": {},
   "source": [
    "underfit models experience high bias- they give inaccurate resulys for both the training data and test set. on the other hand , overfitting models experience high variance-they give accurate results for the training set but the test set. more model training results in less bias but variance can increase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec4f615-7b6c-4830-8a0e-eea09f8286ad",
   "metadata": {},
   "source": [
    "Que2: how can we reduce overfitting ? explain in brief."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86347f42-b0f9-447a-8e6a-6e7975b72158",
   "metadata": {},
   "source": [
    "1. train with more data .2. data augmentation. 3. addition of noise to the input data. 4.feature selection.5. cross-validation. 6.simplify data, 7. regularization, 8. ensembling,9. early stopping,10.adding dropout layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b2c608-2987-4ebf-ba8b-19f9ed322204",
   "metadata": {},
   "source": [
    "Que3: explin underfitting. list scenarios where underfitting can occur in ML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2ae96d-8cfc-4c39-8f2c-f18fe6ae33b3",
   "metadata": {},
   "source": [
    "Ans: underfitting is a scenario in data sceience where a data model is unable to capture the relationship between the input  and output variables accurately,generating a high error rate on both the training set and unseen data.when the training set has far fewer ibservations than variables, this may lead to underfitting or low bias machine leraning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75f5554-da44-4fe7-b9a4-1417a445e01f",
   "metadata": {},
   "source": [
    "Que4: explain the bais-variance tradeoff in machine learning?what is the relation between bias and variance , and how do they affect model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8556159-6a82-454b-8e0d-0fa19642ec7e",
   "metadata": {},
   "source": [
    "Ans: the bais learning treadoff is the property of a madel that the variance of the parameter estimated across samples can be resuced by increasing  the bais in the estimated parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef07ea7-e07a-4c0f-805e-eded06703675",
   "metadata": {},
   "source": [
    "the term \"variance\" refers to the degree of change that may be expected in the estimation of the target function as a result of using muliple sets of treading data. thr disparity between the values that were actually observed is referred to as bais."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59aa084b-4e7f-4b5b-8dcc-a641df92d59f",
   "metadata": {},
   "source": [
    "bias and variance are inversely connected . it is impossible to have an ML model with a low bias and a low variance . when a data engineer modifies the ML algorithm to better fit a given data set, it will lead to low bias-but it will increased variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d7af33-9c3b-4318-8bf6-170e3943229c",
   "metadata": {},
   "source": [
    "Que5: discuss some common methods for detecting overfitting and underfitting in machine learning models.how can you determine wether your models is overfitting or underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586aae60-3b5c-4909-9f63-405ed8e70c66",
   "metadata": {},
   "source": [
    "Ans: regularization : one of the most effective techniques is to use regularization.this involves adding a penalty term to the objective function that the model in order to minimize the adjusted loss functon and prevent overfitting or underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2de389-10cb-4496-9e5c-428d40bb556f",
   "metadata": {},
   "source": [
    "data argumentation: an alternative method to training with more data is data augmentation, which is less expensive and safer than the previous method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68882e7f-102e-4af8-9947-c5e82fee74d4",
   "metadata": {},
   "source": [
    "feature selection: it involves selecting a subset of features from all the extracted features that contributed most towards the model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8a0272-a745-4cee-aa43-adb45b8d445f",
   "metadata": {},
   "source": [
    "remove features: one of the most power/prevent overfitting is cross-validation. although some algorithms have an automatic selection of features. for a significant number of those who do not have a built in feature selection, we can manually remove a few irrelevent features from the input features to improve the generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9abac1a-de39-42bb-8a8b-c0f9dcf5fda5",
   "metadata": {},
   "source": [
    "we can determine whether a predictive model is underfitting and underfitting the training data by looking at the prediction erroe on the training data and the evalution dta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020baf6a-6c99-4007-8052-a7a86cc28090",
   "metadata": {},
   "source": [
    "Que6: compair and contrast bias and variance in machine learning? what are some example of high bias and high variance models, and how do they differ in terms of their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04214536-31cd-4651-84e9-a899efb7e7ec",
   "metadata": {},
   "source": [
    "Ans: bias and variance are inversely connected. it is impossible to have an ML model with a ow bias and a low variance. when a data engineer modles the ML algorithm to better fit a given data set , it will lead to low bais-but it will increace variance.example of high variance MI algorithms include: decision trees, k-nearest neighbors and support vector machines.examples of high bias MI algorithms include: linear regression, linear discriminant analysis and logistic regression.a model with high variance may represents the data set accurately but could lead to overfitting to noisy or otherwise unrepresentative training data. in comparison , a model with high bias may underfit the training data due to a simpler model that overlooks regularities in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c41b93-957d-41ad-af2d-c01fb048b994",
   "metadata": {},
   "source": [
    "Que7: what is regularization in MI , and how can it be used to prevent overfitting ?describe some common regulaozation and how they work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fd6395-1133-4686-abc7-45c9d6afc987",
   "metadata": {},
   "source": [
    "Ans: Regularization refers to tecgniques that are used to calibrate machine learning models in order to minimize the adjusted loss function and prevent overfitting or underfitting.it is a type of regression that minimize the coefficient estimates to zero to reduce the capacity of a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fead603-8337-4157-b592-d48192f185e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "modify loss function: in these regularization tecgnique the loss function under which the model is optimized is modified to directly take into account the norm of the learned parameters .L@ regularization and L1 lagurarizationare loss function based regularization techniqes.2. modify sampling method: these regularization methods try to manipulate the available input to create a fair representation  of the actual input distribution.data augmentation andk-fold creoss-validation. 3. modify training algorithm: the most coomon used methos are a. dropout: dropout is used when the training model is a neura"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
